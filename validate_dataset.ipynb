{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in strong_oak_security_master.csv: Index(['Ticker', 'QUEUESIP', 'Strong Oak Identifier'], dtype='object')\n",
      "Missing values in stock data:\n",
      "RequestId       0\n",
      "Symbol       1580\n",
      "QUEUESIP      522\n",
      "MIC             0\n",
      "dtype: int64\n",
      "Missing values in strong oak data:\n",
      "Ticker                   770\n",
      "QUEUESIP                 368\n",
      "Strong Oak Identifier      0\n",
      "dtype: int64\n",
      "Missing values in attributes data:\n",
      "RequestId                   0\n",
      "Security Name               0\n",
      "Asset Class               514\n",
      "Inception Date            557\n",
      "Return Since Inception    550\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Validation and Breakdown Before Processing\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "stock_df = pd.read_csv('stock.data')\n",
    "exchange_df = pd.read_csv('exchange.data')\n",
    "attributes_df = pd.read_csv('attributes.data')\n",
    "strong_oak_df = pd.read_csv('strong_oak_security_master.csv')\n",
    "\n",
    "# Print the actual column names of the strong_oak_security_master dataset\n",
    "print(\"Columns in strong_oak_security_master.csv:\", strong_oak_df.columns)\n",
    "\n",
    "# Now use the correct column names from the printed output\n",
    "# Check for missing values\n",
    "print(\"Missing values in stock data:\")\n",
    "print(stock_df[['RequestId', 'Symbol', 'QUEUESIP', 'MIC']].isnull().sum())\n",
    "\n",
    "print(\"Missing values in strong oak data:\")\n",
    "print(strong_oak_df[['Ticker', 'QUEUESIP', 'Strong Oak Identifier']].isnull().sum())\n",
    "\n",
    "# Check for missing values in critical columns\n",
    "print(\"Missing values in attributes data:\")\n",
    "print(attributes_df[['RequestId', 'Security Name', 'Asset Class', 'Inception Date', 'Return Since Inception']].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for section1.csv:\n",
      "Missing values in section1 data:\n",
      "EulerId         0\n",
      "MIC             0\n",
      "QUEUESIP      522\n",
      "Symbol       1580\n",
      "RequestId       0\n",
      "dtype: int64\n",
      "Number of rows where both QUEUESIP and Symbol are missing: 0\n",
      "Number of duplicate EulerIds: 0\n",
      "Number of duplicate RequestIds: 0\n",
      "Rows with invalid MIC values (outside of valid list): 0\n",
      "\n",
      "Validation for section2.csv:\n",
      "Missing values in section2 data:\n",
      "EulerId           0\n",
      "AttributeName     0\n",
      "AttributeValue    0\n",
      "dtype: int64\n",
      "Rows in section2 with EulerId not found in section1: 0\n",
      "Duplicate attribute entries in section2 (EulerId, AttributeName): \n",
      "Empty DataFrame\n",
      "Columns: [EulerId, AttributeName, Count]\n",
      "Index: []\n",
      "Rows with invalid AttributeName in section2: 0\n",
      "Rows with invalid Exchange Location format: 0\n"
     ]
    }
   ],
   "source": [
    "# Validation and Breakdown After Processing\n",
    "import pandas as pd\n",
    "\n",
    "# Load the processed section1 and section2 data\n",
    "section1_df = pd.read_csv('Phan_Chenh_section1.csv')\n",
    "section2_df = pd.read_csv('Phan_Chenh_section2.csv')\n",
    "\n",
    "# ---- Validation for section1.csv ----\n",
    "print(\"Validation for section1.csv:\")\n",
    "\n",
    "# Check for missing values in the key columns (EulerId, MIC, QUEUESIP, Symbol, RequestId)\n",
    "print(\"Missing values in section1 data:\")\n",
    "print(section1_df[['EulerId', 'MIC', 'QUEUESIP', 'Symbol', 'RequestId']].isnull().sum())\n",
    "\n",
    "# Ensure at least one of 'QUEUESIP' or 'Symbol' is populated\n",
    "invalid_rows = section1_df[section1_df[['QUEUESIP', 'Symbol']].isnull().all(axis=1)]\n",
    "print(f\"Number of rows where both QUEUESIP and Symbol are missing: {len(invalid_rows)}\")\n",
    "\n",
    "# Ensure there are no duplicate EulerId values\n",
    "duplicate_euler_ids = section1_df['EulerId'].duplicated().sum()\n",
    "print(f\"Number of duplicate EulerIds: {duplicate_euler_ids}\")\n",
    "\n",
    "# Ensure there are no duplicate RequestIds (RequestId should be unique)\n",
    "duplicate_request_ids = section1_df['RequestId'].duplicated().sum()\n",
    "print(f\"Number of duplicate RequestIds: {duplicate_request_ids}\")\n",
    "\n",
    "# ---- Dynamic MIC Validation ----\n",
    "# Get the unique MIC values from the section1 dataset\n",
    "valid_mics = section1_df['MIC'].unique()\n",
    "\n",
    "# Check for rows with invalid MIC values (rows where MIC is not in the list of valid MICs)\n",
    "invalid_mics = section1_df[~section1_df['MIC'].isin(valid_mics)]\n",
    "print(f\"Rows with invalid MIC values (outside of valid list): {len(invalid_mics)}\")\n",
    "\n",
    "# ---- Validation for section2.csv ----\n",
    "print(\"\\nValidation for section2.csv:\")\n",
    "\n",
    "# Check for missing values in AttributeValue (there should be no missing values in AttributeValue)\n",
    "missing_values_section2 = section2_df[['EulerId', 'AttributeName', 'AttributeValue']].isnull().sum()\n",
    "print(\"Missing values in section2 data:\")\n",
    "print(missing_values_section2)\n",
    "\n",
    "# Ensure all EulerId values in section2 exist in section1 (i.e., the EulerId must match between the two files)\n",
    "missing_euler_ids_section2 = section2_df[~section2_df['EulerId'].isin(section1_df['EulerId'])]\n",
    "print(f\"Rows in section2 with EulerId not found in section1: {len(missing_euler_ids_section2)}\")\n",
    "\n",
    "# Check for duplicate attribute names for each EulerId (each EulerId should have only one entry for each attribute)\n",
    "duplicate_attributes = section2_df.groupby(['EulerId', 'AttributeName']).size().reset_index(name='Count')\n",
    "duplicate_attributes = duplicate_attributes[duplicate_attributes['Count'] > 1]\n",
    "print(f\"Duplicate attribute entries in section2 (EulerId, AttributeName): \\n{duplicate_attributes}\")\n",
    "\n",
    "# Ensure that all AttributeNames are valid (must be among the expected attributes)\n",
    "valid_attributes = ['Asset Class', 'Inception Date', 'Exchange Name', 'Exchange Location', 'Security Name', 'Strong Oak Identifier', 'Return Since Inception']\n",
    "invalid_attributes_section2 = section2_df[~section2_df['AttributeName'].isin(valid_attributes)]\n",
    "print(f\"Rows with invalid AttributeName in section2: {len(invalid_attributes_section2)}\")\n",
    "\n",
    "# Check if the combination of 'Exchange Name' and 'Exchange Location' is correct (expected country-city format for location)\n",
    "location_check = section2_df[section2_df['AttributeName'] == 'Exchange Location']\n",
    "invalid_location_format = location_check[~location_check['AttributeValue'].str.contains(' - ')]\n",
    "print(f\"Rows with invalid Exchange Location format: {len(invalid_location_format)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
